This report details the implementation of a large-scale nuclear astrophysics simulation aimed at obtaining reaction rates using the TALYS software. These simulations are computationally intensive and can be time-consuming if executed sequentially. To address this challenge, the code leverages parallel programming techniques with MPI (Message Passing Interface), enabling significant reductions in runtime and enhancing the overall efficiency of the simulation process.

MPI facilitates the division of the computational workload across multiple processors, allowing the simulation to be executed concurrently on several cores. This approach drastically speeds up the computation, making it possible to handle large datasets and complex simulations more effectively. In this implementation, the MPI communicator initializes multiple processes, each of which is assigned a unique rank and a specific subset of data to process. By distributing the workload, the simulation can run on several processors simultaneously, minimizing the time required to obtain the reaction rates.

Each process executes the TALYS command for its designated elements and masses, independently capturing the output and handling potential errors. The results from all processes are then gathered and combined by the root process (rank 0) to ensure that the output is correctly organized and stored. This method not only saves time but also makes the simulation process more scalable, enabling the efficient handling of large-scale nuclear astrophysics calculations.

Please note that certain portions of the code related to the specific TALYS configuration and input parameters have been redacted in this report for research purposes. This redaction ensures the confidentiality of ongoing research while still demonstrating the application of MPI in this context.
